import os
import pandas as pd
import psycopg2
import re
from PIL import Image
from fuzzywuzzy import fuzz
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
import tempfile
import uvicorn
from dotenv import load_dotenv
from sqlalchemy import create_engine
import google.generativeai as genai
import json
import nest_asyncio

# Memuat variabel lingkungan dari file .env
load_dotenv()

# Mengambil variabel lingkungan. Menggunakan DB_DB untuk konsistensi.
DB_NAME = os.getenv("DB_DB")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")
GEMINI_API_KEY = os.getenv("GOOGLE_API_KEY")

class KeywordNormalizer:
    """Class untuk mengelola dan melakukan normalisasi keywords dari database."""
    def __init__(self):
        self.keywords_map = {}
        self.load_keywords()

    def load_keywords(self):
        """Memuat keyword normalisasi dari database."""
        self.keywords_map.clear()
        try:
            with psycopg2.connect(
                dbname=DB_NAME,
                user=DB_USER,
                password=DB_PASSWORD,
                host=DB_HOST,
                port=DB_PORT
            ) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("SELECT keyword, normalized_value FROM keywords")
                    rows = cursor.fetchall()
                    for keyword, normalized_value in rows:
                        self.keywords_map[keyword.lower()] = normalized_value.lower()
            print("Keywords berhasil dimuat dari database.")
        except Exception as e:
            print(f"Error loading keywords from DB: {e}")

    def normalize_text(self, text: str) -> tuple[str, dict]:
        """Normalisasi teks dan identifikasi typo."""
        original_words = re.findall(r'\b\w+\b', text.lower())
        normalized_words = []
        typos = {}

        for word in original_words:
            if word in self.keywords_map:
                normalized_value = self.keywords_map[word]
                typos[word] = normalized_value
                normalized_words.append(normalized_value)
            else:
                normalized_words.append(word)

        normalized_text = " ".join(normalized_words)
        return normalized_text, typos

    def add_keyword_to_db(self, keyword: str, normalized_value: str):
        """Menambahkan keyword baru ke database lalu update map di memori."""
        try:
            with psycopg2.connect(
                dbname=DB_NAME,
                user=DB_USER,
                password=DB_PASSWORD,
                host=DB_HOST,
                port=DB_PORT
            ) as conn:
                with conn.cursor() as cursor:
                    cursor.execute("""
                        INSERT INTO keywords (keyword, normalized_value)
                        VALUES (%s, %s)
                        ON CONFLICT (keyword) DO UPDATE SET normalized_value = EXCLUDED.normalized_value
                    """, (keyword.lower(), normalized_value.lower()))
                    conn.commit()
            self.keywords_map[keyword.lower()] = normalized_value.lower()
            print(f"Keyword '{keyword}' berhasil ditambahkan/diperbarui di database.")
        except Exception as e:
            print(f"Error adding keyword to DB: {e}")

def load_data_pusat():
    """Memuat data dari tabel data_pusat."""
    try:
        engine = create_engine(f"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}")
        # PERBAIKAN: Menambahkan argumen `con=engine`
        df = pd.read_sql_query("SELECT id, description, brand FROM public.data_pusat", con=engine)
        df = df.dropna()
        descriptions = df["description"].astype(str).str.lower().tolist()
        data_list = df.to_dict('records')
        print("Data pusat berhasil dimuat.")
        return df, descriptions, data_list
    except Exception as e:
        print(f"Error loading data from DB: {e}")
        return pd.DataFrame(), [], []

# Konfigurasi Gemini API
genai.configure(api_key=GEMINI_API_KEY)
model_gemini = genai.GenerativeModel("gemini-2.5-flash")

def OCR_Gemini(image_path: str) -> dict:
    """Melakukan OCR pada gambar struk menggunakan Gemini API."""
    try:
        img = Image.open(image_path)
        prompt = """
        Ini adalah struk belanja. Tolong ekstrak informasinya dalam format JSON dengan field:
        - invoice_number (string)
        - phone (string)
        - alamat (string)
        - email (string)
        - nama_toko (string)
        - tanggal (string, format DD/MM/YYYY)
        - daftar_barang (array of objects: nama, qty, harga_satuan, subtotal)
        - total_belanja (number)
        Jika ada informasi yang tidak jelas, isi dengan null.
        Hanya kembalikan JSON-nya saja, tanpa penjelasan atau markdown formatting.
        """
        response = model_gemini.generate_content([prompt, img])
        text = response.text
        cleaned = re.sub(r'^```json|```$', '', text, flags=re.MULTILINE).strip()
        return json.loads(cleaned)
    except Exception as e:
        print(f"Error during Gemini OCR: {e}")
        return {"daftar_barang": []}

def match_items(items: list, descriptions: list, data_list: list, normalizer: KeywordNormalizer, threshold: int = 58) -> list:
    """Mencocokkan item OCR dengan data pusat."""
    allowed_brands = ["nivea", "biore", "posh", "khaf"]
    result = []
    
    for item in items:
        ocr_item_name = item.get('nama', '').lower()
        normalized_name, typos = normalizer.normalize_text(ocr_item_name)
        typo_dict = {f"additionalProp{i+1}": val for i, (key, val) in enumerate(typos.items())}

        best_score = 0
        best_match_data = None
        
        for i, desc in enumerate(descriptions):
            score = fuzz.token_set_ratio(normalized_name, desc)
            if score > best_score:
                best_score = score
                best_match_data = data_list[i]

        is_brand_allowed = (
            best_match_data is not None and best_match_data.get("brand", "").lower() in allowed_brands
        )
        
        is_match_found = best_score >= threshold and is_brand_allowed

        item_result = {
            "id": int(best_match_data.get("id")) if is_match_found and best_match_data else 0,
            "name": best_match_data.get("description") if is_match_found and best_match_data else "",
            "data": best_match_data.get("brand") if is_match_found and best_match_data else "",
            "ocr_result": {
                "name": item.get('nama', ''),
                "quantity": float(item.get('qty', 0) or 0),
                "price": float(item.get('harga_satuan', 0) or 0),
                "total": float(item.get('subtotal', 0) or 0),
                "accuration": round(best_score / 100, 4) if is_match_found else 0.0,
                "typo": typo_dict,
                "normalisasi": normalized_name,
                "hasil": "benar" if is_match_found else "salah"
            }
        }
        result.append(item_result)
    return result

# --- Pydantic Models untuk FastAPI ---
class OCRResult(BaseModel):
    name: Optional[str]
    quantity: Optional[float]
    price: Optional[float]
    total: Optional[float]
    accuration: Optional[float]
    typo: Optional[Dict[str, str]]
    normalisasi: Optional[str]
    hasil: Optional[str]

class ItemMatched(BaseModel):
    id: Optional[int]
    name: Optional[str]
    data: Optional[str]
    ocr_result: OCRResult

class Merchant(BaseModel):
    name: Optional[str]
    address: Optional[str]
    phone: Optional[str]
    email: Optional[str]

class FinalOutput(BaseModel):
    invoice_number: Optional[str]
    tanggal: Optional[str]
    merchant: Optional[Merchant]
    items: List[ItemMatched]
    grand_total: Optional[float]

class NormalizationRequest(BaseModel):
    keyword: str
    normalized_value: str

# --- Inisialisasi Aplikasi FastAPI ---
app = FastAPI()
df, descriptions, data_list = load_data_pusat()
normalizer = KeywordNormalizer()

@app.post("/struk-batch", response_model=List[FinalOutput])
async def struk_batch(files: List[UploadFile] = File(...)):
    results = []
    for file in files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
            tmp.write(await file.read())
            path = tmp.name

        try:
            OCRData = OCR_Gemini(path)
            items = OCRData.get('daftar_barang', [])
            matched = match_items(items, descriptions, data_list, normalizer)

            result = {
                "invoice_number": OCRData.get('invoice_number'),
                "tanggal": OCRData.get('tanggal'),
                "merchant": {
                    "name": OCRData.get('nama_toko'),
                    "address": OCRData.get('alamat'),
                    "phone": OCRData.get('phone'),
                    "email": OCRData.get('email')
                },
                "items": matched,
                "grand_total": float(OCRData.get('total_belanja', 0)) if OCRData.get('total_belanja') is not None else 0
            }
            results.append(result)
        except Exception as e:
            print(f"Error processing file {file.filename}: {e}")
            results.append({
                "error": f"Failed to process file {file.filename}.",
                "detail": str(e)
            })
        finally:
            try:
                os.remove(path)
            except Exception as e:
                print(f"Gagal menghapus file {path}: {e}")
    return results

@app.post("/add-normalization")
def add_normalization(data: NormalizationRequest):
    """Endpoint untuk menambahkan keyword normalisasi baru ke DB"""
    normalizer.add_keyword_to_db(data.keyword, data.normalized_value)
    return {
        "message": f"Normalisasi '{data.keyword}' -> '{data.normalized_value}' berhasil disimpan ke DB"
    }

@app.get("/")
def health_check():
    return {"status": "running"}

if __name__ == "__main__":
    nest_asyncio.apply()
    # PERBAIKAN: Mengganti "strok" menjadi "struk"
    uvicorn.run("strok:app", host="127.0.0.1", port=8000, reload=True)


createTable.py
import os
import pandas as pd
import psycopg2
from psycopg2 import errors
from dotenv import load_dotenv

# Memuat variabel lingkungan dari file .env
load_dotenv()

# Mengambil variabel lingkungan. Menggunakan DB_DB untuk konsistensi.
DB_NAME = os.getenv("DB_DB")
DB_USER = os.getenv("DB_USER")
DB_PASSWORD = os.getenv("DB_PASSWORD")
DB_HOST = os.getenv("DB_HOST")
DB_PORT = os.getenv("DB_PORT")

def create_database_if_not_exists():
    """
    Membuat database PostgreSQL jika belum ada.
    Terhubung ke database default 'postgres' untuk menjalankan perintah ini.
    """
    try:
        with psycopg2.connect(
            dbname="postgres",
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT
        ) as conn:
            conn.autocommit = True
            with conn.cursor() as cursor:
                cursor.execute("SELECT 1 FROM pg_database WHERE datname = %s", (DB_NAME,))
                exists = cursor.fetchone()

                if not exists:
                    cursor.execute(f'CREATE DATABASE "{DB_NAME}"')
                    print(f"Database '{DB_NAME}' berhasil dibuat.")
                else:
                    print(f"Database '{DB_NAME}' sudah ada.")
    except Exception as e:
        print(f"Error saat membuat database: {e}")

def setup_tables_and_triggers():
    """
    Menyiapkan tabel dan triggers yang diperlukan di database target.
    """
    try:
        with psycopg2.connect(
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT
        ) as conn:
            with conn.cursor() as cursor:
                # --- Membuat Tabel data_pusat ---
                # Mengubah tipe data harga_ppn dan harga_jual_saran ke NUMERIC
                # agar sesuai dengan data dari Excel.
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS data_pusat (
                    id SERIAL PRIMARY KEY,
                    brand TEXT,
                    sub_brand_as TEXT,
                    brand_group_as TEXT,
                    description TEXT,
                    barcode_pieces NUMERIC UNIQUE,
                    harga_ptt NUMERIC,
                    qty_per_carton BIGINT,
                    harga_ppn NUMERIC,
                    harga_jual_saran NUMERIC
                );
                """)
                print("Tabel data_pusat siap digunakan.")

                # --- Membuat Tabel keywords ---
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS keywords (
                    id SERIAL PRIMARY KEY,
                    keyword TEXT NOT NULL UNIQUE,
                    normalized_value TEXT NOT NULL,
                    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
                );
                """)
                print("Tabel keywords siap digunakan.")

                # --- Membuat Tabel ocr_items ---
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS ocr_items (
                    id SERIAL PRIMARY KEY,
                    invoice_number TEXT,
                    tanggal DATE,
                    nama_toko TEXT,
                    alamat TEXT,
                    phone TEXT,
                    email TEXT,
                    total_belanja NUMERIC,
                    is_confirmed BOOLEAN DEFAULT FALSE,
                    feedback TEXT,
                    created_at TIMESTAMP DEFAULT NOW(),
                    confirmed_at TIMESTAMP
                );
                """)
                print("Tabel ocr_items siap digunakan.")

                # --- Membuat Tabel ocr_results ---
                cursor.execute("""
                CREATE TABLE IF NOT EXISTS ocr_results (
                    id SERIAL PRIMARY KEY,
                    receipt_id INTEGER REFERENCES ocr_items(id) ON DELETE CASCADE,
                    ocr_name TEXT,
                    ocr_quantity NUMERIC,
                    ocr_price NUMERIC,
                    ocr_total NUMERIC,
                    text_accuracy NUMERIC,
                    price_accuracy NUMERIC,
                    final_score NUMERIC,
                    matched_item_id INTEGER REFERENCES data_pusat(id),
                    matched_price NUMERIC,
                    matched_name TEXT,
                    keywords TEXT[],
                    is_correct BOOLEAN,
                    feedback TEXT,
                    confirmed_at TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
                """)
                print("Tabel ocr_results siap digunakan.")

                # --- Fungsi dan Triggers (Diperiksa keberadaannya sebelum dibuat) ---
                cursor.execute("""
                CREATE OR REPLACE FUNCTION update_timestamp()
                RETURNS TRIGGER AS $$
                BEGIN
                    NEW.updated_at = NOW();
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;
                
                DO $$
                BEGIN
                    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_keywords_timestamp') THEN
                        CREATE TRIGGER update_keywords_timestamp
                        BEFORE UPDATE ON keywords
                        FOR EACH ROW
                        EXECUTE FUNCTION update_timestamp();
                    END IF;
                END
                $$;
                
                DO $$
                BEGIN
                    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'update_ocr_results_timestamp') THEN
                        CREATE TRIGGER update_ocr_results_timestamp
                        BEFORE UPDATE ON ocr_results
                        FOR EACH ROW
                        EXECUTE FUNCTION update_timestamp();
                    END IF;
                END
                $$;
                
                CREATE OR REPLACE FUNCTION update_ocr_item_confirmation()
                RETURNS TRIGGER AS $$
                DECLARE
                    all_confirmed BOOLEAN;
                BEGIN
                    SELECT BOOL_AND(is_correct IS NOT NULL) INTO all_confirmed
                    FROM ocr_results
                    WHERE receipt_id = NEW.receipt_id;

                    IF all_confirmed THEN
                        UPDATE ocr_items
                        SET is_confirmed = TRUE, confirmed_at = NOW()
                        WHERE id = NEW.receipt_id;
                    END IF;
                    RETURN NEW;
                END;
                $$ LANGUAGE plpgsql;

                DO $$
                BEGIN
                    IF NOT EXISTS (SELECT 1 FROM pg_trigger WHERE tgname = 'check_all_items_confirmed') THEN
                        CREATE TRIGGER check_all_items_confirmed
                        AFTER INSERT OR UPDATE ON ocr_results
                        FOR EACH ROW
                        EXECUTE FUNCTION update_ocr_item_confirmation();
                    END IF;
                END
                $$;
                """)
                conn.commit()
                print("Semua triggers berhasil disiapkan.")

    except psycopg2.OperationalError as e:
        print(f"Error koneksi ke database: {e}. Pastikan database '{DB_NAME}' sudah dibuat.")
    except Exception as e:
        print(f"Error saat menyiapkan tabel dan triggers: {e}")

def load_data_from_files():
    """
    Memuat data dari file Excel dan teks ke dalam database.
    """
    try:
        with psycopg2.connect(
            dbname=DB_NAME,
            user=DB_USER,
            password=DB_PASSWORD,
            host=DB_HOST,
            port=DB_PORT
        ) as conn:
            with conn.cursor() as cursor:
                # --- Muat data dari file Excel ke data_pusat ---
                excel_files = [
                    ('SKU.xlsx', 'All NIVEA PL Mei 2024'),
                    ('wingsfood.xlsx', 'All WINGSFOOD 2024')
                ]
                for excel_file, sheet_name in excel_files:
                    try:
                        df = pd.read_excel(excel_file, usecols=range(9), skiprows=2, sheet_name=sheet_name)
                        df.rename(columns=lambda x: x.strip(), inplace=True)
                        df = df.dropna()

                        cursor.execute("SELECT COUNT(*) FROM data_pusat")
                        count = cursor.fetchone()[0]

                        if count == 0:
                            for _, row in df.iterrows():
                                cursor.execute("""
                                    INSERT INTO data_pusat (
                                        brand, sub_brand_as, brand_group_as, description, barcode_pieces,
                                        harga_ptt, qty_per_carton, harga_ppn, harga_jual_saran
                                    )
                                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                                    ON CONFLICT (barcode_pieces) DO NOTHING;
                                """, (
                                    row.get('Brand'),
                                    row.get('Sub Brand AS'),
                                    row.get('Brand Group AS'),
                                    row.get('Description'),
                                    str(row.get('Barcode (Pieces)')),
                                    row.get('Harga PTT/Sebelum PPN'),
                                    row.get('Kuantiti per Karton/Dus'),
                                    row.get('Harga PPN'),
                                    row.get('Harga Jual ke Konsumen yg Disarankan')
                                ))
                            conn.commit()
                            print(f"Data dari '{excel_file}' berhasil dimasukkan.")
                        else:
                            print(f"Tabel data_pusat sudah berisi data. Melewatkan insert dari '{excel_file}'.")
                    except FileNotFoundError:
                        print(f"Error: File Excel '{excel_file}' tidak ditemukan.")
                    except Exception as e:
                        print(f"Error saat membaca/menyisipkan data Excel: {e}")
                        conn.rollback()

                # --- Muat data normalisasi.txt ke keywords ---
                normalisasi_file = 'normalisasi.txt'
                if os.path.exists(normalisasi_file):
                    inserted_count = 0
                    with open(normalisasi_file, 'r', encoding='utf-8') as f:
                        for line in f:
                            line = line.strip()
                            if not line or '=' not in line:
                                continue
                            keyword, normalized = line.split('=', 1)
                            cursor.execute("""
                                INSERT INTO keywords (keyword, normalized_value)
                                VALUES (%s, %s)
                                ON CONFLICT (keyword) DO NOTHING;
                            """, (keyword.strip().lower(), normalized.strip().lower()))
                            if cursor.rowcount > 0:
                                inserted_count += 1
                    conn.commit()
                    print(f"{inserted_count} keywords dari '{normalisasi_file}' berhasil dimasukkan.")
                else:
                    print(f"File '{normalisasi_file}' tidak ditemukan.")

    except psycopg2.OperationalError as e:
        print(f"Error koneksi ke database: {e}. Pastikan database '{DB_NAME}' sudah dibuat.")
    except Exception as e:
        print(f"Error saat memuat data: {e}")

if __name__ == "__main__":
    create_database_if_not_exists()
    setup_tables_and_triggers()
    load_data_from_files()
    print("Skrip inisialisasi database selesai.")
